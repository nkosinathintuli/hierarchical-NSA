{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1072,
   "id": "b5d9267d-024e-46ec-8225-8c0c1a5667d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8375fd59-7237-4440-b58a-020f2b5a57d4",
   "metadata": {},
   "source": [
    "#### Functions\n",
    "\n",
    "1. User-preferences Weights Calculations - Fuzzy Logic\n",
    "2. Service QoS Weights Calculations - AHP\n",
    "3. Normalisation \n",
    "4. Final Weights Calculation RAT layer\n",
    "5. MEW\n",
    "6. SAW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f524c1-d2ca-482f-aef2-045330fed6db",
   "metadata": {},
   "source": [
    "#### 1. Fuzzy Membership Funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "id": "ca28e724-90a6-4fb6-81ac-ed6a91ee1e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_membership(criteria_value, preference, min_value, max_value):\n",
    "    \"\"\"\n",
    "    Calculate the fuzzy membership value for a given criteria.\n",
    "    \n",
    "    :param criteria_value: The value of the criteria to evaluate\n",
    "    :param preference: 'low', 'medium', or 'high'\n",
    "    :param min_value: The minimum value for the criteria range\n",
    "    :param max_value: The maximum value for the criteria range\n",
    "    :return: Membership value between 0 and 1\n",
    "    \"\"\"\n",
    "    \n",
    "    def low_mf(x, b, c):\n",
    "        return np.where(x <= b, 1, max(0, (c - x) / (c - b)))\n",
    "    \n",
    "    def medium_mf(x, a, b, c):\n",
    "        return max(0, min((x - a) / (b - a), (c - x) / (c - b)))\n",
    "    \n",
    "    def high_mf(x, a, b):\n",
    "        return np.where(x >= b, 1, max(0, (x - a) / (b - a)))\n",
    "    \n",
    "    # Calculate the range\n",
    "    value_range = max_value - min_value\n",
    "\n",
    "    preference = preference.lower()\n",
    "    # Set ratios for a, b, c based on the range\n",
    "    if preference == 'low':\n",
    "        b = min_value + 0.25 * value_range\n",
    "        c = min_value + 0.5 * value_range\n",
    "        return low_mf(criteria_value, b, c)\n",
    "    \n",
    "    elif preference == 'medium':\n",
    "        a = min_value + 0.25 * value_range\n",
    "        b = min_value + 0.5 * value_range\n",
    "        c = min_value + 0.75 * value_range\n",
    "        return medium_mf(criteria_value, a, b, c)\n",
    "    \n",
    "    elif preference == 'high':\n",
    "        a = min_value + 0.5 * value_range\n",
    "        b = min_value + 0.75 * value_range\n",
    "        return high_mf(criteria_value, a, b)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Preference must be 'low', 'medium', or 'high'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "id": "6a41090a-20d1-47c9-aab7-d6f84692dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qos_to_no(preference: str) -> float:\n",
    "    \"\"\"\n",
    "    Convert a QoS preference string to its corresponding numerical value.\n",
    "    \n",
    "    Args:\n",
    "    preference (str): A string representing the QoS preference. \n",
    "                      Must be either \"Low\", \"Medium\", or \"High\" (case-insensitive).\n",
    "    \n",
    "    Returns:\n",
    "    float: The numerical value corresponding to the preference.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If an invalid preference is provided.\n",
    "    \"\"\"\n",
    "    preference_map = {\n",
    "        \"low\": 0.01,\n",
    "        \"medium\": 0.50,\n",
    "        \"high\": 0.99\n",
    "    }\n",
    "    \n",
    "    normalized_preference = preference.lower()\n",
    "    \n",
    "    if normalized_preference not in preference_map:\n",
    "        raise ValueError(\"Invalid preference. Must be 'Low', 'Medium', or 'High'.\")\n",
    "    \n",
    "    return preference_map[normalized_preference]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce67d48-aca9-44fe-addb-bc551b1df271",
   "metadata": {},
   "source": [
    "#### 2. AHP Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "e2fe292e-b70b-435e-8429-4313d15a2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ahp_weights(matrix):\n",
    "    \"\"\"\n",
    "    Calculate weights and Consistency Index for AHP pairwise comparison matrix.\n",
    "    \n",
    "    Args:\n",
    "    matrix (np.array): Square pairwise comparison matrix\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (weights, consistency_index)\n",
    "    \"\"\"\n",
    "    # Check if the matrix is square\n",
    "    if matrix.shape[0] != matrix.shape[1]:\n",
    "        raise ValueError(\"Matrix must be square\")\n",
    "    \n",
    "    n = matrix.shape[0]\n",
    "    \n",
    "    # Calculate the principal eigenvalue and eigenvector\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(matrix)\n",
    "    max_index = np.argmax(eigenvalues)\n",
    "    max_eigenvalue = eigenvalues[max_index].real\n",
    "    eigenvector = eigenvectors[:, max_index].real\n",
    "    \n",
    "    # Normalize the eigenvector to get the weights\n",
    "    weights = eigenvector / np.sum(eigenvector)\n",
    "    \n",
    "    # Calculate the Consistency Index\n",
    "    ci = (max_eigenvalue - n) / (n - 1)\n",
    "    \n",
    "    # Calculate the Random Index\n",
    "    ri_values = {1: 0, 2: 0, 3: 0.58, 4: 0.9, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49}\n",
    "    ri = ri_values.get(n, 1.49)  # Use 1.49 for n > 10\n",
    "    \n",
    "    # Calculate the Consistency Ratio\n",
    "    cr = ci / ri if ri != 0 else 0\n",
    "    if cr >= 0.1:\n",
    "        raise ValueError(\"Not Consistent!\")\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f998588-692a-428a-97fc-16721608a3bb",
   "metadata": {},
   "source": [
    "#### 3. Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "id": "d47eb935-d633-4810-b9f3-fe62e9efb832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_root_normalize(matrix, criteria_types):\n",
    "    \"\"\"\n",
    "    Normalize the matrix using square root normalization,\n",
    "    accounting for upward and downward criteria.\n",
    "    \n",
    "    :param matrix: numpy array of shape (n_rats, n_criteria)\n",
    "    :param criteria_types: list of strings, either 'up' or 'down' for each criterion\n",
    "    :return: normalized matrix\n",
    "    \"\"\"\n",
    "    normalized = np.zeros_like(matrix, dtype=float)\n",
    "    \n",
    "    for j in range(matrix.shape[1]):\n",
    "        if criteria_types[j] == 'up':\n",
    "            normalized[:, j] = matrix[:, j] / np.sqrt(np.sum(matrix[:, j]**2))\n",
    "        elif criteria_types[j] == 'down':\n",
    "            normalized[:, j] = 1 - (matrix[:, j] / np.sqrt(np.sum(matrix[:, j]**2)))\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid criterion type: {criteria_types[j]}. Must be 'up' or 'down'.\")\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def minmax_normalize(matrix, criteria_types):\n",
    "    \"\"\"\n",
    "    Normalize RAT criteria matrix using Max-Min function.\n",
    "    \n",
    "    :param matrix: 2D numpy array where each row represents a RAT and each column a criterion\n",
    "    :param criteria_types: List of strings ('up' or 'down') indicating whether each criterion is upward or downward\n",
    "    :return: Normalized matrix\n",
    "    \"\"\"\n",
    "    normalized = np.zeros_like(matrix, dtype=float)\n",
    "    \n",
    "    for j in range(matrix.shape[1]):\n",
    "        column = matrix[:, j]\n",
    "        col_min, col_max = np.min(column), np.max(column)\n",
    "        if col_min == col_max:\n",
    "            col_min -= 1\n",
    "        \n",
    "        if criteria_types[j] == 'up':\n",
    "            normalized[:, j] = 1 - abs(column - col_max) / (col_max - col_min)\n",
    "        elif criteria_types[j] == 'down':\n",
    "            normalized[:, j] = 1 - abs(column - col_min) / (col_max - col_min)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid criterion type for column {j}. Must be 'up' or 'down'.\")\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923a03c-3bec-45bb-91b0-86c41e654ec9",
   "metadata": {},
   "source": [
    "#### 4. Final Weights Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff1273-f181-4678-bfe6-1a51d9f44a55",
   "metadata": {},
   "source": [
    "#### 5. MEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "id": "286feed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mew_scores(decision_matrix, weights):\n",
    "    \"\"\"\n",
    "    Calculate scores using the Multiple Exponen Weighted (MEW) method.\n",
    "    \n",
    "    Parameters:\n",
    "    decision_matrix (numpy.ndarray): A normalized decision matrix where rows represent alternatives and columns represent criteria.\n",
    "    weights (numpy.ndarray): An array of weights for each criterion.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: An array of MEW scores for each alternative.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure inputs are numpy arrays\n",
    "    decision_matrix = np.array(decision_matrix)\n",
    "    weights = np.array(weights)\n",
    "    \n",
    "    # Check if the number of weights matches the number of criteria\n",
    "    if decision_matrix.shape[1] != weights.shape[0]:\n",
    "        raise ValueError(\"The number of weights must match the number of criteria (columns) in the decision matrix.\")\n",
    "    \n",
    "    # Calculate MEW scores\n",
    "    weighted_matrix = np.power(decision_matrix, weights)\n",
    "    mew_scores = np.prod(weighted_matrix, axis=1)\n",
    "    \n",
    "    return mew_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "id": "ae5fa8b6-4113-421a-9112-10d1e270a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_mew_scores(decision_matrix, weights_matrix):\n",
    "    \"\"\"\n",
    "    Calculate scores using the Multiple Exponential Weighted (MEW) method with individual weights for each alternative.\n",
    "    \n",
    "    Parameters:\n",
    "    decision_matrix (numpy.ndarray): A normalized decision matrix where rows represent alternatives and columns represent criteria.\n",
    "    weights_matrix (numpy.ndarray): A matrix of weights where each row corresponds to weights for the respective alternative.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: An array of MEW scores for each alternative.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure inputs are numpy arrays\n",
    "    decision_matrix = np.array(decision_matrix)\n",
    "    weights_matrix = np.array(weights_matrix)\n",
    "    \n",
    "    # Check if the dimensions of the decision matrix and weights matrix match\n",
    "    if decision_matrix.shape != weights_matrix.shape:\n",
    "        raise ValueError(\"The dimensions of the decision matrix and weights matrix must match.\")\n",
    "    \n",
    "    # Calculate MEW scores\n",
    "    weighted_matrix = np.power(decision_matrix, weights_matrix)\n",
    "    mew_scores = np.prod(weighted_matrix, axis=1)\n",
    "    \n",
    "    return mew_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d6dae-8cc8-42ba-8bcd-d8d4ef82c00f",
   "metadata": {},
   "source": [
    "#### 6. SAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "id": "2e4f5e3f-31ee-48a6-aeee-b87de52da99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_saw_scores(decision_matrix, weights):\n",
    "    \"\"\"\n",
    "    Calculate scores using the Simple Additive Weighting (SAW) method.\n",
    "    \n",
    "    Parameters:\n",
    "    decision_matrix (numpy.ndarray): A normalized decision matrix where rows represent alternatives and columns represent criteria.\n",
    "    weights (numpy.ndarray): An array of weights for each criterion.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: An array of SAW scores for each alternative.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure inputs are numpy arrays\n",
    "    decision_matrix = np.array(decision_matrix)\n",
    "    weights = np.array(weights)\n",
    "    \n",
    "    # Check if the number of weights matches the number of criteria\n",
    "    if decision_matrix.shape[1] != weights.shape[0]:\n",
    "        raise ValueError(\"The number of weights must match the number of criteria (columns) in the decision matrix.\")\n",
    "    \n",
    "    # Calculate SAW scores\n",
    "    saw_scores = np.sum(decision_matrix * weights, axis=1)\n",
    "    \n",
    "    return saw_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff5dee-6f9b-4e30-9258-c3918e7452e6",
   "metadata": {},
   "source": [
    "#### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "id": "da5ed195-d7d2-4cb3-a799-a7b119ad7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"simulation_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae9a87-dc31-41e2-bb25-e4254583618c",
   "metadata": {},
   "source": [
    "Decision Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "id": "eb58539e-692c-43a9-8339-85cfcaae7c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path+\"/decision_matrix.csv\",header = None)\n",
    "P_max = np.max(df[1][1:6].values.astype(np.float64))\n",
    "P_min = np.min(df[1][1:6].values.astype(np.float64))\n",
    "C_max = np.max(df[2][1:6].values.astype(np.float64))\n",
    "C_min = np.min(df[2][1:6].values.astype(np.float64))\n",
    "#print(P_max, P_min, C_max, C_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "id": "a44a2674-b7c7-402a-a929-705049ab77d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RATs = df[0][1:6].values\n",
    "\n",
    "criteria_types = df.iloc[6:,1:].values[0]\n",
    "\n",
    "dm_rat = df.iloc[1:6,1:7].values.astype(np.float64)\n",
    "dm_ap = df.iloc[1:6,7:11].values.astype(np.float64)\n",
    "\n",
    "\n",
    "normal_dm_rat = square_root_normalize(dm_rat, criteria_types[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00aa003-ae1a-416c-b6d2-e52085745579",
   "metadata": {},
   "source": [
    "Service QoS Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "id": "21390f8d-04d4-4658-9dc2-9d8a53bda734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path+\"/pairwise_matrices.csv\",header = None)\n",
    "services = df[0].iloc[[0, 7, 14, 21]].values\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "services_weights = np.zeros((4,4)) # 4 services, 4 criteria\n",
    "\n",
    "rows_per_matrix = len(df) // 4\n",
    "\n",
    "for i in range(services_weights.shape[0]):\n",
    "    df_service = df.iloc[rows_per_matrix * i : (rows_per_matrix * (i+1))].iloc[1:5,1:5] # if i<3 else 0\n",
    "    services_weights[i] = ahp_weights(df_service.values.astype(np.float64))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c247d92d-a901-48cb-901f-d4d15717d608",
   "metadata": {},
   "source": [
    "User Preferences Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "id": "18c9de10-b8e6-4d71-b2bf-2cb56d56292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path+\"/user_preferences.csv\", index_col = 0)\n",
    "users_prefs = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "id": "d2fce88a-8d3b-4731-ae38-a40d958d87d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pref_weights(criteria, user_prefs):\n",
    "    userpref_weights = np.zeros(3)\n",
    "    userpref_weights[0] = qos_to_no(user_prefs[0])\n",
    "    userpref_weights[1] = fuzzy_membership(criteria[0],user_prefs[1],P_min,P_max)\n",
    "    userpref_weights[2] = fuzzy_membership(criteria[1],user_prefs[2],C_min,C_max) #price range across alt 0.01 - 10 $/Gb\n",
    "    return userpref_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "id": "9eba5fd3-be57-483d-bc3f-19cffedd365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def userspref_weights(criteria, users_prefs): # returns a matrix of weights user [1...U] x prefs [Q,P,C]\n",
    "    userspref_weights = np.zeros_like(users_prefs)\n",
    "    #print(userspref_weights)\n",
    "    for i in range(users_prefs.shape[0]):\n",
    "        userspref_weights[i] = pref_weights(criteria[:2],users_prefs[i])\n",
    "        #print(pref_weights(criteria[:2],users_prefs[i]))\n",
    "        #print(userpref_weights[i])\n",
    "    return userspref_weights #27x3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "id": "b685c01e-8738-41c8-a7a3-1ab52749aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qos_nomarlisation(user_weights, service_weights):\n",
    "    normal_uw = user_weights[1:] if np.sum(user_weights[1:]) <= 0 else user_weights[1:]/np.sum(user_weights[1:])\n",
    "    return np.concatenate((normal_uw * (1 - user_weights[0]) , service_weights * user_weights[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "id": "787edd08-2aed-4c8c-acea-c4af9fd9d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def users_service_weights(criteria, users_prefs, services_weights):\n",
    "    weights = np.zeros((27,4,6))\n",
    "    p_and_c = criteria[:2]\n",
    "\n",
    "    usersprefs_w = userspref_weights(p_and_c, users_prefs) # 27x3 matrix of weights\n",
    "    for i in range(27):\n",
    "        for j in range(4):\n",
    "            weights[i][j] = qos_nomarlisation(usersprefs_w[i],services_weights[j])\n",
    "    return weights # comprehisive weights for each user per service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "id": "aff14bef-628e-4fed-b740-40577a0fd0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rat_users_weights(rat_matrix, users_prefs, services_weights, service):\n",
    "\n",
    "    rat_user_weights =  np.zeros((5,27,6))\n",
    "\n",
    "    for i in range(5):# for each RAT compute the user weights for each user 5x27    \n",
    "        rat_user_weights[i] = users_service_weights(rat_matrix[i],users_prefs,services_weights)[:, service, :] # service 1 at index 0\n",
    "        #print(rat_user_weights[0])\n",
    "        #print(users_service_weights(dm_rat[i],users_prefs,services_weights)[:, 0, :])\n",
    "    return rat_user_weights # 5x27x6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca1a74",
   "metadata": {},
   "source": [
    "Investigating the distribution of the 27 unique users across the RATs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "id": "ab841183-4557-489b-b7c7-63992e03d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_1_freq = np.zeros((4,5), dtype=np.int64)\n",
    "\n",
    "for i in range(services.size):\n",
    "    scores = np.zeros((27,5))\n",
    "    rat_user_weights = rat_users_weights(dm_rat, users_prefs, services_weights, i) \n",
    "\n",
    "    for j in range(27):\n",
    "        scores[j] = modified_mew_scores(normal_dm_rat, rat_user_weights[:,j,:]) # 27x5 \n",
    "        rank_1_freq[i] += scores[j]==np.max(scores[j])\n",
    "        #print((scores[i]==np.max(scores[i])))\n",
    "        #print(scores[i])\n",
    "\n",
    "\n",
    "df_user_per_rat = pd.DataFrame(rank_1_freq, columns=RATs, index=services)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "id": "6f49f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pie(rank_1_freq, labels=RATs, autopct='%1.1f%%')\n",
    "# plt.title('Distribution of Users Across Networks')\n",
    "# plt.show()\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "# for i, service in enumerate(services):\n",
    "#     row = i // 2\n",
    "#     col = i % 2\n",
    "#     ax = axes[row, col]\n",
    "\n",
    "#     # Extract data for the current service\n",
    "#     network_names = RATs\n",
    "#     user_counts = rank_1_freq[i]\n",
    "\n",
    "#     # Create the pie chart\n",
    "#     ax.pie(user_counts, labels=network_names, autopct='%1.1f%%')\n",
    "#     ax.set_title(f'{service}')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8287b34",
   "metadata": {},
   "source": [
    "Investigating the RAT rankings per service type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "id": "3b5c5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_weights = np.array([0.5,0.5,0.5]) # equal weights for each user preference criteria\n",
    "# services_weights\n",
    "weights_for_services = np.zeros((4,6))\n",
    "\n",
    "for i in range(4):\n",
    "    weights_for_services[i] = qos_nomarlisation(user_weights,services_weights[i])\n",
    "\n",
    "\n",
    "weights_for_services.shape\n",
    "RAT_scores = np.zeros((4,5)) # 4 services, 5 RATs\n",
    "\n",
    "for i in range(4):\n",
    "    RAT_scores[i] = mew_scores(normal_dm_rat, weights_for_services[i])\n",
    "\n",
    "ranks = np.zeros((4,5), dtype=np.int64)\n",
    "for i in range(4): \n",
    "    ranks[i] = np.argsort(RAT_scores[i])[::-1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "id": "024f166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rank = pd.DataFrame(ranks, columns=RATs, index=services)\n",
    "\n",
    "# df_rank.plot(kind='bar', figsize=(10, 6))\n",
    "# plt.xlabel('RATs')\n",
    "# plt.ylabel('Rank')\n",
    "# plt.title('Rank of RATs by Service')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc5b4af",
   "metadata": {},
   "source": [
    "Investigate the sensitivity of the user preference weights on RAT scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "id": "277396b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 1000\n",
    "\n",
    "var_weight = np.linspace(0,1,samples)\n",
    "\n",
    "userpref_criteria = np.array(['QoS','Power Consumption','Cost']) # Q, P, C\n",
    "user_weights = np.array([0.5,0.5,0.5]) # equal weights for each user preference criteria, Q, P, C\n",
    "\n",
    "RAT_scores = np.zeros((user_weights.size,samples,5)) # 1000 samples, 5 RATs, 3 user weights\n",
    "\n",
    "\n",
    "# for user weight Q, P, C plot a var_weight vs RAT_scores\n",
    "for i in range(user_weights.size):\n",
    "    user_weights = np.array([0.1,0.1,0.1]) # equal weights for each user preference criteria, Q, P, C\n",
    "    for j in range(samples):\n",
    "        user_weights[i] = var_weight[j]\n",
    "        weights = qos_nomarlisation(user_weights,services_weights[3]) # service 4: Equal Importance \n",
    "        RAT_scores[i][j] = mew_scores(normal_dm_rat, weights) #\n",
    "\n",
    "# for i in range(samples):\n",
    "#     user_weights[1] = var_weight[i]\n",
    "#     weights = qos_nomarlisation(user_weights,services_weights[3])\n",
    "#     RAT_scores[i] = mew_scores(normal_dm_rat, weights)\n",
    "\n",
    "# RAT_scores[0]\n",
    "# df = pd.DataFrame(RAT_scores[2], columns=RATs)\n",
    "# df\n",
    "#plot a line graph \n",
    "\n",
    "# df.plot(figsize=(10, 6))\n",
    "# plt.xlabel('QoS')\n",
    "# plt.ylabel('Score')\n",
    "# plt.title('RAT Scores vs QoS')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "id": "5953e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up the plot\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(15, 15))\n",
    "# fig.suptitle('RAT Scores vs Criterion Weights', fontsize=16)\n",
    "\n",
    "# # Flatten the axs array for easier indexing\n",
    "# axs = axs.flatten()\n",
    "\n",
    "\n",
    "# # Plot each criterion\n",
    "# for i, criterion in enumerate(userpref_criteria):\n",
    "#     ax = axs[i]\n",
    "#     for j, rat in enumerate(RATs):\n",
    "#         ax.plot(var_weight, RAT_scores[i, :, j], label=rat)\n",
    "#         #print(RAT_scores[i, :, j])\n",
    "#         #print(j)\n",
    "    \n",
    "#     ax.set_xlabel('Weight')\n",
    "#     ax.set_ylabel('Score')\n",
    "#     ax.set_title(f'{criterion} Weight vs RAT Scores')\n",
    "#     ax.legend()\n",
    "#     ax.grid(True)\n",
    "\n",
    "# # Remove the unused subplot\n",
    "# axs[3].remove()\n",
    "\n",
    "# # Adjust layout and show the plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cb60d5",
   "metadata": {},
   "source": [
    "Investigate the sensitivity of the threshold percentage on the number of RATs selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "id": "37e4be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a RAT filtering function based on a percentage threshold\n",
    "def RAT_filter(RAT_scores,percentage,RATs):\n",
    "    threshold = np.max(RAT_scores) * percentage\n",
    "    \n",
    "    df = pd.DataFrame(RAT_scores, RATs)\n",
    "    filtered_RATs = df[df[0] > threshold]\n",
    "    return filtered_RATs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "id": "49763727",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_weights = np.array([0.5,0.5,0.5]) # equal weights for each user preference criteria\n",
    "weights = qos_nomarlisation(user_weights,services_weights[1]) # service 4: Equal Importance\n",
    "\n",
    "RAT_scores = mew_scores(normal_dm_rat, weights)\n",
    "\n",
    "percentage = np.linspace(0, 1, 100)\n",
    "\n",
    "number_of_RATs = np.zeros(percentage.size)\n",
    "for i in range(percentage.size):\n",
    "    number_of_RATs[i] = RAT_filter(RAT_scores,percentage[i],RATs).shape[1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "id": "e1d69469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create 2x2 subplots\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(15, 15))\n",
    "# fig.suptitle('Number of RATs vs Threshold for Different Services', fontsize=16)\n",
    "\n",
    "# # Flatten the axs array for easier indexing\n",
    "# axs = axs.flatten()\n",
    "\n",
    "# for idx, service in enumerate(services):\n",
    "#     user_weights = np.array([0.5, 0.5, 0.5])  # equal weights for each user preference criteria\n",
    "#     weights = qos_nomarlisation(user_weights, services_weights[idx])\n",
    "    \n",
    "#     # Placeholder for normal_dm_rat, replace with actual data\n",
    "#     #normal_dm_rat = np.random.rand(10, 3)  # Assuming 10 RATs and 3 QoS parameters\n",
    "    \n",
    "#     RAT_scores = mew_scores(normal_dm_rat, weights)\n",
    "    \n",
    "#     percentage = np.linspace(0, 1, 100)\n",
    "#     number_of_RATs = np.zeros(percentage.size)\n",
    "    \n",
    "#     for i in range(percentage.size):\n",
    "#         number_of_RATs[i] = RAT_filter(RAT_scores, percentage[i], RAT_scores).size\n",
    "    \n",
    "#    # Create step-like data points\n",
    "#     x_steps = np.repeat(percentage, 2)[1:]\n",
    "#     y_steps = np.repeat(number_of_RATs, 2)[:-1]\n",
    "    \n",
    "#     # Add the first and last points to close the shape\n",
    "#     x_steps = np.concatenate(([0], x_steps, [1]))\n",
    "#     y_steps = np.concatenate(([number_of_RATs[0]], y_steps, [0]))\n",
    "    \n",
    "#     axs[idx].fill_between(x_steps*100, y_steps, step=\"pre\" ) \n",
    "#     axs[idx].plot(x_steps*100, y_steps, color='blue', linewidth=0.5, drawstyle='steps-post')\n",
    "#     axs[idx].set_xlabel('Threshold[%]')\n",
    "#     axs[idx].set_ylabel('Number of RATs')\n",
    "#     axs[idx].set_title(f'{service}')\n",
    "#     axs[idx].grid(True)\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a789e",
   "metadata": {},
   "source": [
    "Investigate the number of cells selected per RAT. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "id": "770c49cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_weights(decision_matrix):\n",
    "    weights = np.random.rand(decision_matrix.shape[1])\n",
    "    return weights\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def entropy_weighting(decision_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the entropy-based weights for criteria in a decision matrix.\n",
    "\n",
    "    Parameters:\n",
    "    decision_matrix (numpy.ndarray): Matrix where each row is an alternative and each column is a criterion.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Array of weights for each criterion.\n",
    "    \"\"\"\n",
    "    # Step 1: Normalize the decision matrix\n",
    "    normalized_matrix = decision_matrix / decision_matrix.sum(axis=0)\n",
    "    \n",
    "    # Step 2: Calculate the entropy for each criterion\n",
    "    # Small epsilon to avoid log(0) error\n",
    "    epsilon = 1e-12\n",
    "    n, m = decision_matrix.shape\n",
    "    k = 1 / np.log(n)\n",
    "    \n",
    "    # Calculate the entropy for each criterion\n",
    "    entropy = -k * (normalized_matrix * np.log(normalized_matrix + epsilon)).sum(axis=0)\n",
    "    \n",
    "    # Step 3: Calculate the degree of divergence (1 - entropy)\n",
    "    divergence = 1 - entropy\n",
    "    \n",
    "    # Step 4: Calculate the weights for each criterion\n",
    "    weights = divergence / divergence.sum()\n",
    "    \n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "id": "6a218363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['6G'], dtype='object')"
      ]
     },
     "execution_count": 1100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAT_filter(RAT_scores,0.9,RATs).columns\n",
    "#df.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_weights(decision_matrix):\n",
    "    weights = np.random.rand(decision_matrix.shape[1])\n",
    "    return weights\n",
    "\n",
    "def identify_constant_columns(matrix):\n",
    "  \"\"\"\n",
    "  Identifies constant columns in a matrix.\n",
    "\n",
    "  Args:\n",
    "    matrix: A NumPy array.\n",
    "\n",
    "  Returns:\n",
    "    A list of column indices that have constant values.\n",
    "  \"\"\"\n",
    "\n",
    "  constant_columns = []\n",
    "  for col_idx in range(matrix.shape[1]):\n",
    "    if np.all(matrix[:, col_idx] == matrix[0, col_idx]):\n",
    "      constant_columns.append(col_idx)\n",
    "  return constant_columns\n",
    "\n",
    "\n",
    "def critic_weighting(decision_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the CRITIC-based weights for criteria in a decision matrix.\n",
    "\n",
    "    Parameters:\n",
    "    decision_matrix (numpy.ndarray): Matrix where each row is an alternative and each column is a criterion.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Array of weights for each criterion.\n",
    "    \"\"\"\n",
    "    # Step 1: Normalize the decision matrix\n",
    "    max_values = decision_matrix.max(axis=0)\n",
    "    #print(max_values)\n",
    "    max_values[max_values == 0] = 1  # Avoid division by zero\n",
    "    #print(max_values)\n",
    "    normalized_matrix = decision_matrix /max_values\n",
    "    #print(normalized_matrix)\n",
    "    const_cols = identify_constant_columns(normalized_matrix)\n",
    "    \n",
    "    # To avoid division by zero, replace constant columns with random values\n",
    "    for col in const_cols:\n",
    "        normalized_matrix[:, col] = np.random.rand(normalized_matrix.shape[0]) \n",
    "        \n",
    "    \n",
    "    # Step 2: Calculate the standard deviation for each criterion\n",
    "    std_devs = np.std(normalized_matrix, axis=0)\n",
    "    \n",
    "    # Correcting the std deviation for constant columns\n",
    "    for col in const_cols:\n",
    "        std_devs[col] = 0 # the std value for constant values is 0\n",
    "    \n",
    "    # Step 3: Calculate the correlation matrix between criteria\n",
    "    correlation_matrix = np.corrcoef(normalized_matrix, rowvar=False)\n",
    "    #print(correlation_matrix)\n",
    "    \n",
    "    # correcting the correlation matrix for constant columns\n",
    "    for col in const_cols:\n",
    "        correlation_matrix[col] = 0\n",
    "        correlation_matrix[:, col] = 0\n",
    "    \n",
    "\n",
    "    #print(correlation_matrix)\n",
    "    # Step 4: Calculate the degree of conflict for each criterion\n",
    "    conflict = 1 - correlation_matrix\n",
    "    conflict_sum = conflict.sum(axis=1)  # Sum across each row (for each criterion)\n",
    "\n",
    "    # Step 5: Calculate the information measure for each criterion (std_devs * conflict_sum)\n",
    "    information_measure = std_devs * conflict_sum\n",
    "\n",
    "    # Step 6: Normalize the information measure to get the final weights\n",
    "    weights = information_measure / information_measure.sum()\n",
    "\n",
    "    return weights\n",
    "\n",
    "def entropy_weighting(decision_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the entropy-based weights for criteria in a decision matrix.\n",
    "\n",
    "    Parameters:\n",
    "    decision_matrix (numpy.ndarray): Matrix where each row is an alternative and each column is a criterion.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Array of weights for each criterion.\n",
    "    \"\"\"\n",
    "    # Step 1: Normalize the decision matrix\n",
    "    normalized_matrix = decision_matrix / decision_matrix.sum(axis=0)\n",
    "    \n",
    "    # Step 2: Calculate the entropy for each criterion\n",
    "    # Small epsilon to avoid log(0) error\n",
    "    epsilon = 1e-12\n",
    "    n, m = decision_matrix.shape\n",
    "    k = 1 / np.log(n)\n",
    "    \n",
    "    # Calculate the entropy for each criterion\n",
    "    entropy = -k * (normalized_matrix * np.log(normalized_matrix + epsilon)).sum(axis=0)\n",
    "    \n",
    "    # Step 3: Calculate the degree of divergence (1 - entropy)\n",
    "    divergence = 1 - entropy\n",
    "    \n",
    "    # Step 4: Calculate the weights for each criterion\n",
    "    weights = divergence / divergence.sum()\n",
    "    \n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "id": "bd9d1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_SINR():\n",
    "    return round(np.random.uniform(0, 40), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "id": "b9807ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5G</th>\n",
       "      <td>2</td>\n",
       "      <td>0.974338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5G</th>\n",
       "      <td>6</td>\n",
       "      <td>0.931180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5G</th>\n",
       "      <td>1</td>\n",
       "      <td>0.902019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5G</th>\n",
       "      <td>3</td>\n",
       "      <td>0.883356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5G</th>\n",
       "      <td>8</td>\n",
       "      <td>0.863527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5G</th>\n",
       "      <td>4</td>\n",
       "      <td>0.813370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5G</th>\n",
       "      <td>5</td>\n",
       "      <td>0.780710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5G</th>\n",
       "      <td>10</td>\n",
       "      <td>0.778377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5G</th>\n",
       "      <td>7</td>\n",
       "      <td>0.752716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5G</th>\n",
       "      <td>9</td>\n",
       "      <td>0.655901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6G</th>\n",
       "      <td>1</td>\n",
       "      <td>0.346432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6G</th>\n",
       "      <td>7</td>\n",
       "      <td>0.307939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6G</th>\n",
       "      <td>9</td>\n",
       "      <td>0.295108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6G</th>\n",
       "      <td>8</td>\n",
       "      <td>0.283444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6G</th>\n",
       "      <td>3</td>\n",
       "      <td>0.281111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6G</th>\n",
       "      <td>2</td>\n",
       "      <td>0.263615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6G</th>\n",
       "      <td>5</td>\n",
       "      <td>0.150470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6G</th>\n",
       "      <td>4</td>\n",
       "      <td>0.135307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6G</th>\n",
       "      <td>6</td>\n",
       "      <td>0.069986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6G</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1\n",
       "5G   2  0.974338\n",
       "5G   6  0.931180\n",
       "5G   1  0.902019\n",
       "5G   3  0.883356\n",
       "5G   8  0.863527\n",
       "5G   4  0.813370\n",
       "5G   5  0.780710\n",
       "5G  10  0.778377\n",
       "5G   7  0.752716\n",
       "5G   9  0.655901\n",
       "6G   1  0.346432\n",
       "6G   7  0.307939\n",
       "6G   9  0.295108\n",
       "6G   8  0.283444\n",
       "6G   3  0.281111\n",
       "6G   2  0.263615\n",
       "6G   5  0.150470\n",
       "6G   4  0.135307\n",
       "6G   6  0.069986\n",
       "6G  10  0.000000"
      ]
     },
     "execution_count": 1103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path+\"/decision_matrix.csv\",header = None)\n",
    "# number of AP/BSs per RAT\n",
    "M  = 10\n",
    "# AP/BSs capacity\n",
    "C = 10\n",
    "# number of users\n",
    "U = 100\n",
    "selected_RATs = RAT_filter(RAT_scores,0.5,RATs).columns\n",
    "no_of_RATs = selected_RATs.size\n",
    "\n",
    "\n",
    "# Create a matrix of AP/BS criteria values for each RAT\n",
    "\n",
    "APs = np.zeros((no_of_RATs, M, dm_ap.shape[1]))\n",
    "all_APs = np.zeros((no_of_RATs*M, dm_ap.shape[1]))\n",
    "RAT_AP = []\n",
    "cell_nos = np.ones(no_of_RATs*M, dtype=np.int64)\n",
    "\n",
    "# fill the APs matrix with APs for each selected RAT         \n",
    "for i in range(no_of_RATs):\n",
    "    rat = selected_RATs[i]\n",
    "    selected_row = df[df.iloc[:, 0] == rat].iloc[0][7:].values.astype(np.float64)\n",
    "    RAT_AP += [rat] * 10\n",
    "    for j in range(M):\n",
    "        selected_row[2] = random_SINR() # \n",
    "        APs[i, j] = selected_row\n",
    "        all_APs[j+i*M] = selected_row\n",
    "        cell_nos[j+i*M] = j+1\n",
    "\n",
    "\n",
    "#print(all_APs)\n",
    "\n",
    "\n",
    "\n",
    "normal_ap = minmax_normalize(all_APs, criteria_types[6:])\n",
    "weights = critic_weighting(all_APs)\n",
    "AP_scores = calculate_saw_scores(normal_ap,weights)\n",
    "#normal_ap\n",
    "\n",
    "#all_APs.max(axis=0)\n",
    "\n",
    "weights\n",
    "# # Create a dictionary to store the number of APs/BSs per RAT\n",
    "# APs_per_RAT = {rat: 10 for rat in selected_RATs}\n",
    "# APs_per_RAT\n",
    "\n",
    "AP_scores\n",
    "RAT_AP\n",
    "\n",
    "df = pd.DataFrame(list(zip(cell_nos,AP_scores)),index=RAT_AP, )\n",
    "df.sort_values(by=1, ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
